{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiQGo4Gfydzh",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class='bar_title'></div>\n",
    "\n",
    "*Introduction to Data Science*\n",
    "\n",
    "# Modeling (aka. Machine Learning)\n",
    "\n",
    "Gunther Gust<br>\n",
    "Chair of Enterprise AI\n",
    "\n",
    "Winter Semester 24/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6YntqqTydzi"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/GuntherGust/tds2_data/main/images/d3.png?raw=1\" style=\"width:20%; float:left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FmJUl6kydzi",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/vhaus63/ids_data/main/ao_modeling.png\" style=\"width:80%\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_xOz6Kkydzi",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "## Building a machine learning pipeline\n",
    "\n",
    "* Data Selection\n",
    "* Model Training\n",
    "* Model Evaluation\n",
    "* Hyperparameter Tuning\n",
    "* Data Cleaning\n",
    "* Combining everything in a pipeline\n",
    "\n",
    "Credits: Most of the material of this lecture is adopted from www.kaggle.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LXm8I7Eydzj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scenario: Real estate price predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avw4pEKQydzj"
   },
   "source": [
    "\n",
    "This lecture provides an overview of how machine learning models can be used for real problems. We will build models as well as a machine learning pipeline based on the following scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUeAuiM1ydzj",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Your cousin has made millions of dollars speculating on real estate. He's offered to become business partners with you because of your interest in data science. He'll supply the money, and you'll supply models that predict how much various houses are worth.\n",
    "\n",
    "You ask your cousin how he's predicted real estate values in the past and he says it is just intuition. But more questioning reveals that he's identified price patterns from houses he has seen in the past, and he uses those patterns to make predictions for new houses he is considering.\n",
    "\n",
    "Instead of using intuition to make good decision, we want to train a __machine learning model to predict the value of new houses__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJx1tovbydzj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the Data\n",
    "The first step in any machine learning project is to load and familiarize yourself with the data. To this end, we can use the pandas library from last week and load the dataset with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HB5qY1UQydzk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "Z3Of11zcydzl",
    "outputId": "ef44321a-05f1-49f1-8c1f-e705b182afc6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melbourne_file_path = 'https://raw.githubusercontent.com/vhaus63/ids_data/refs/heads/main/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "melbourne_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nKd74XOydzl",
    "outputId": "f901843e-3d7f-494a-9894-fe5e2db259b6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "melbourne_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b0ilUVKydzl",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Removing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8S4I6kMydzl"
   },
   "source": [
    "For simplicity we remove rows with missing values for this example. Note that a missing value can sometimes be a valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAwZoy5eydzl",
    "outputId": "3aea9e32-c692-4465-e6be-67888cc0cdd3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(melbourne_data.shape)\n",
    "melbourne_data.dropna(axis=0, inplace=True)\n",
    "print(melbourne_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYHmRs67ydzm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Select data for modeling\n",
    "On a first glimpse, we see that our dataset has too many variables to wrap our heads around. How can we pare down this overwhelming amount of data to something we can understand?\n",
    "\n",
    "We'll start by picking a few variables using our intuition. To choose variables, we'll need to see a list of all columns in the dataset. That is done with the columns property of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydvEU8Icydzm",
    "outputId": "5824188c-5918-4b13-f203-781898a6ceb9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "melbourne_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2ipvu-Jydzm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Selecting the prediction target\n",
    "\n",
    "To train a predictive model using supervised machine learning techniques, we have to identify the target variable. In the problem at hand, we want to predict the house prices. This information is encoded in the column Price.\n",
    "\n",
    "By convention, the target variable is called **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRssVccKydzm"
   },
   "outputs": [],
   "source": [
    "y = melbourne_data['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N30eEjSTydzm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing \"Features\"\n",
    "The columns that serve as input for our model (and are later used to make predictions) are called \"features.\" Sometimes, you will use all columns except the target as features. Other times you'll be better off with fewer features.\n",
    "\n",
    "For now, we'll build a model with only a few features.\n",
    "\n",
    "We select multiple features by providing a list of column names inside brackets. Each item in that list should be a string (with quotes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jc7d2bjOydzm"
   },
   "outputs": [],
   "source": [
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea',\n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iElb0PvMydzm",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By convention, this data is called **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19pFwwHPydzm"
   },
   "outputs": [],
   "source": [
    "X = melbourne_data[melbourne_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XQJmEreydzn",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uzU4VV2ydzn"
   },
   "source": [
    "Let's quickly review the data we'll be using to predict house prices using the describe method and the head method, which shows the top few rows. Visually checking your data with these commands is an important part of a data scientist's job. You'll frequently find surprises in the dataset that deserve further inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "jWQtMdTfydzn",
    "outputId": "a8a8d2bc-017b-4ac2-c310-a58b6749b5b7",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "aM72_wWaydzn",
    "outputId": "88ecf775-efde-42e6-d50d-9f4d6ad8b655",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In data science, a model is a simplified representation or abstraction of reality that uses mathematical or statistical techniques to capture __patterns, relationships, or structures in data.__ \n",
    "\n",
    "- __Data-driven:__ Models are built and validated using data.\n",
    "- __Simplification:__ Models are not perfect replicas of reality but are designed to approximate it for a __specific purpose.__ \n",
    "- __Model classes:__ Purposes fall into the classes of:\n",
    "    - Description\n",
    "    - Prediction\n",
    "    - Prescription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/vhaus63/ids_data/main/analytics_types.png\" style=\"width:80%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src=\"https://raw.githubusercontent.com/vhaus63/ids_data/main/analytics_value_chain.png\" style=\"width:80%\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Models can also be distinguished by the __way their are created__ (\"learned\", \"trained\", \"fitted\") from the data into __supervised, unsupervised and reinforcement learning__ models: \n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/vhaus63/ids_data/main/machine_learning_types.jpg\" style=\"width:80%\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. **Supervised Learning**\n",
    "Supervised learning models are trained on __labeled data,__ where both inputs (features) and outputs (targets) are known. The goal is to map inputs to outputs accurately.\n",
    "\n",
    "- __Regression models:__ Predict a __continuous numerical output.__ Examples: Forecasting house prices, stock market values, or temperature.\n",
    "\n",
    "- __Classification models:__ Predict a __categorical label or class.__ Examples: Identifying whether an email is spam or not, or classifying images as cats or dogs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. **Unsupervised Learning**\n",
    "Unsupervised learning models are trained on __unlabeled data,__ with the goal of discovering __patterns or groupings__ within the data. The models learn inherent data structures without predefined labels. \n",
    "\n",
    "- Example: Use clustering techniques like k-Means to segment customers for targeted marketing strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 3. **Reinforcement Learning**\n",
    "Reinforcement learning models learn by __interacting__ with an environment and __receiving feedback__ in the form of rewards or penalties. The goal is to maximize cumulative rewards over time through trial and error.\n",
    "\n",
    "- Example: Optimize product prices dynamically by reacting to observed demand in order to maximize revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcWBuXBAydzn",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building Models in Scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zwnekezydzn"
   },
   "source": [
    "For now, we will use the scikit-learn library to create our models. As you will see in the upcoming section, this library is written as sklearn in the code. Scikit-learn offers a lot of powerful features and is easily the most popular library for modeling tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98u3827Xydzn",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The steps to building and using a model in Scikit-learn are:\n",
    "* __Define__:  What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n",
    "* __Fit__: Capture patterns from our input data.\n",
    "* __Predict__: Make predictions using input variables and the trained model.\n",
    "* __Evaluate__: Determine how accurate the model's predictions are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5lZ_jtVydzn",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Our first decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mw3dgSxfydzn"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/GuntherGust/tds2_data/main/images/03/decision-tree.avif?raw=1\" style=\"width:60%; float:left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDNtOueBydzn",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Background on decision trees\n",
    "\n",
    "- Please watch [this series of youtube videos](https://www.youtube.com/playlist?list=PLblh5JKOoLUKAtDViTvRGFpphEc24M-QH) to learn how decision trees work. <span style=\"color:red\">__This content is relevant for the exam!__</span>\n",
    "- For a formal coverage see [Hastie et al: Elements of Statistical Learning, Chapter 9.2](https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebIPEig9ydzo",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is a simple example of defining a decision tree model with scikit-learn and fitting it with the features and target variable selected above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "YlmrHwqeydzo",
    "outputId": "d2ccf3af-23ba-45fb-bfc4-4d1288525add"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit\n",
    "melbourne_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AW0X_lTUydzo",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Many machine learning models allow some randomness in model training. Specifying a number for random_state ensures you get the same results in each run. This is considered a good practice. You use any number, and model quality won't depend meaningfully on exactly what value you choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1x8xMw2ydzo",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We now have a fitted model that we can use to make predictions.\n",
    "\n",
    "In practice, you'll want to make predictions for new houses coming on the market rather than the houses we already have prices for. But we'll make predictions for the first few rows of the training data to see how the predict function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjQLasBvydzo",
    "outputId": "907e7f2a-c483-4184-c322-10c8d852fc32",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(melbourne_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub7VtW9-ydzo",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXA2JeVYydzs"
   },
   "source": [
    "We have successfully trained our very first model. However, we have no clue how good our model is. Yet, measuring model quality is the key to iteratively improving our models.\n",
    "\n",
    "In most (though not all) applications, the relevant measure of model quality is predictive accuracy. In other words, will the model's predictions be close to what actually happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjrIa1AEydzs",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Validation Metric: Mean absolute error (MAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oa_G6C1Lydzs"
   },
   "source": [
    "To evaluate the performance of our model we need to find a way to summarize the model quality in an understandable way. If we compare predicted and actual home values in our example dataset for 10,000 houses, we will find a mix of good and bad predictions. However, looking through a list of 10,000 predicted and actual values would be pointless. We need to summarize this into a single metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LLH13soydzs",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "``Mean absolute error (MAE) = Mean (|actual price − predicted price|)``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JFtTETzydzs"
   },
   "source": [
    "There are many metrics for summarizing model quality, but we'll start with one called Mean Absolute Error (**MAE**). Let's break down this metric starting with the last word, error.\n",
    "\n",
    "The prediction error for each house is:\n",
    "\n",
    "``error=actual−predicted``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mn1Vr9haydzs",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, if a house cost 150,000 Euros and you predicted it would cost 100,000 Dollars the error is 50,000 Dollars.\n",
    "\n",
    "With the MAE metric, we take the absolute value of each error. This converts each error to a positive number. We then take the average of those absolute errors. This is our measure of model quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVvbX3VXydzs"
   },
   "source": [
    "We could implement a function to calculate this metric (or any other metric) on our dataframe. However, Scikit-learn provides implementations of the most common metrics that can be easily imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTB3twNwydzt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SU3qkfAKydzt"
   },
   "source": [
    "So lets use our decision tree model to make predictions for all observations in our dataset and calculate the MAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSjgagP5ydzt",
    "outputId": "64ce5032-fad0-42e8-e564-682ef271d23c",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mae = mean_absolute_error(y, predicted_home_prices)\n",
    "\n",
    "print(\"The MAE of our model is: {}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other common validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### **Mean Squared Error (MSE)**\n",
    "The **Mean Squared Error** measures the average squared difference between predicted values (`y_hat`) and actual values (`y`).\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "n \\text{ : Number of observations} \\\\\n",
    "y_i \\text{ : Actual value} \\\\\n",
    "\\hat{y}_i \\text{ : Predicted value}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "####  **Root Mean Squared Error (RMSE)**\n",
    "The **Root Mean Squared Error** is the square root of the MSE. It represents the error in the same units as the target variable, making it __more interpretable.__\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### **Mean Absolute Percentage Error (MAPE)**\n",
    "The **Mean Absolute Percentage Error** measures the average percentage difference between predicted values and actual values. It is __scale-independent,__ expressed as a percentage.\n",
    "\n",
    "$$\n",
    "\\text{MAPE} = \\frac{1}{n} \\sum_{i=1}^n \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\times 100\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "1. Create an additional evaluation function that evaluates the __root mean squared error (RMSE)__ instead of the mean absolute error (MAE). Hint: Look again in the scikit-learn documentation for help.\n",
    "\n",
    "3. Compare the resulting RMSE with the MAE. How do you interpret the differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your intepretation here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "To evaluate the performance of a classification model, the __confusion matrix__ and __derived metrics__ are used. The confusion matrix provides a clear breakdown of the model's __predictions compared to the actual outcomes.__ Here's an explanation of its components:\n",
    "\n",
    "\n",
    "\n",
    "|                     | **Predicted Positive** | **Predicted Negative** |\n",
    "|---------------------|-------------------------|-------------------------|\n",
    "| **Actual Positive** | True Positive (TP)     | False Negative (FN)     |\n",
    "| **Actual Negative** | False Positive (FP)    | True Negative (TN)      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "### Definitions:\n",
    "- **True Positive (TP)**: The model correctly predicts the positive class.\n",
    "- **False Positive (FP)**: The model incorrectly predicts the positive class for an actual negative.\n",
    "- **False Negative (FN)**: The model incorrectly predicts the negative class for an actual positive.\n",
    "- **True Negative (TN)**: The model correctly predicts the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metrics Derived from the Confusion Matrix:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Accuracy\n",
    "The **Accuracy** measures the proportion of correct predictions (both positive and negative) to the total number of predictions.\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "**Use Case**:  \n",
    " Accuracy is useful when the dataset is __balanced,__ and the correct prediction of all classes is equally important. Example: A bank uses a model to predict loan approvals ensuring both approvals and rejections are correctly predicted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision\n",
    "\n",
    "The **Precision** measures the proportion of true positive predictions out of all predicted positive cases. \n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "**Use Case**: It focuses on reducing __false positives.__ Example: A spam filter evaluates flagged emails. High precision ensures fewer legitimate emails are incorrectly moved to the spam folder (**False Positives**).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall (Sensitivity)\n",
    "\n",
    "The **Recall** measures the proportion of actual positive cases correctly identified by the model. It focuses on minimizing false negatives.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "**Use Case**:  \n",
    "A cancer detection system ensures high recall, minimizing missed diagnoses (**False Negatives**) to catch as many positive cases as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### F1 Score\n",
    "\n",
    "The **F1 Score** is the harmonic mean of Precision and Recall. It balances both metrics and is particularly useful for imbalanced datasets.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "**Use Case**:  \n",
    "In manufacturing, the F1 Score ensures that defective products are accurately identified, balancing false positives and false negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are __many more metrics__ derived from the confusion matrix, each with specific purposes. [Wikipedia](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers) provides a nice overview:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/vhaus63/ids_data/main/confusion_matrix_wikipedia.png\" style=\"width:80%\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9k0oaVDydzt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In-Sample vs. Out-of-Sample Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnpfHSDnydzt"
   },
   "source": [
    "The MAE of our model looks __very promising__. However, we used a single \"sample\" of houses for both building the model and evaluating it. Hence, the measure we just computed can be called an __\"in-sample\" score__.\n",
    "\n",
    "Trusting the in-sample score to evaluate a model is __very dangerous__. Imagine that there is a variable in the dataset that is unrelated to the home price (e.g., the name of the current owner). However, in the sample of data we used to build the model, all names are unique and hence, all house prices in the sample can be explained by this feature. Our model will see this pattern and it will try to apply it to new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcEHAGssydzt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since models' practical value come from making predictions on __new data__, we measure performance on data that wasn't used to build the model. The most straightforward way to do this is to exclude some data from the model-building process, and then use those to test the model's accuracy on data it hasn't seen before. This data is called __validation data__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waZWO4g2ydzt"
   },
   "source": [
    "\n",
    "<img src=\"https://raw.githubusercontent.com/GuntherGust/tds2_data/main/images/03/4_train-test-split.jpg?raw=1\" style=\"width:80%; float:left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdLgDAbIydzt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Backround on data splits for training and validating machine learning models\n",
    "\n",
    "\n",
    "- For an informal and illustrative introduction, see [this youtube video](https://www.youtube.com/watch?v=fSytzGwwBVw&ab_channel=StatQuestwithJoshStarmer)\n",
    "- For a formal coverage see [Hastie et al: Elements of Statistical Learning, Chapter 7](https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjOKmZ3Sydzt",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The scikit-learn library has a function train_test_split to break up the data into two pieces. We'll use some of that data as training data to fit the model, and we'll use the other data as validation data to calculate the MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LQ-MLwlydzt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IV0nFa3nydzt",
    "outputId": "2459286c-b21b-4a96-d9ea-e8325e9654f3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Build the model\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# Evaluate the performance\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_y, val_predictions)\n",
    "\n",
    "print(\"The MAE of our model is: {}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkKXafBoydzu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The MAE for the in-sample data was about __500 Dollars__. Out-of-sample it is __more than 250,000 Dollars__.\n",
    "\n",
    "This is the difference between a model that is almost exactly right, and one that is unusable for most practical purposes. As a point of reference, the average home value in the validation data is about __1.1 million dollars__. So the error in new data is about __a quarter__ of the average home value.\n",
    "\n",
    "There are many ways to __tune and improve this model__, such as experimenting to find better features or different model types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQgh73KUydzu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise \n",
    "\n",
    "1. Repeat the previous model training using a linear regression instead of the decision tree. Hint: Check out the [scikit-learn documentation](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html), where the  regression model is decribed and code examples are given.\n",
    "2. How do you interpret the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1YCTOXGsydzu",
    "outputId": "ab579400-27cb-454c-e687-b5ac22661ac1"
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Rabn2oS0Yc8"
   },
   "source": [
    "_Answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Regression Models\n",
    "\n",
    "To recap the basic functioning of linear regression models, please watch these videos [(1) Linear Regression](https://www.youtube.com/watch?v=nk2CQITm_eo&list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU&index=4&ab_channel=StatQuestwithJoshStarmer) and [(2) Multiple Regression](https://www.youtube.com/watch?v=zITIFTsivN8&list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU&index=4&ab_channel=StatQuestwithJoshStarmer).  <span style=\"color:red\">__This content is relevant for the exam!__</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObRGsPTAydzu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Tuning (aka. \"Hyperparameter Tuning\")\n",
    "\n",
    "### Example: Varying the Depth of the Decision Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rKRSZB9ydzu"
   },
   "source": [
    "Now that we have a reliable way to measure the model performance, we can experiment with different parameters of the decision tree (or entirely different models) and see which combination gives us the best predictions. You can find the available models and parameters in the Scikit-learn [documentation](https://scikit-learn.org/stable/modules/classes.html).\n",
    "\n",
    "In this simple example we will stick with our decision tree model and only vary one of the parameters.\n",
    "\n",
    "You can see in the decision tree [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) that the model has many parameters (more than you'll want or need for a long time). The most important parameters determine the tree's depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cBTLipPydzu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In practice, it's not uncommon for a tree to have 10 splits between the top level (all houses) and a leaf. As the tree gets deeper, the dataset gets sliced up into leaves with fewer houses. If a tree only had 1 split, it divides the data into 2 groups. If each group is split again, we would get 4 groups of houses. Splitting each of those again would create 8 groups. If we keep doubling the number of groups by adding more splits at each level, we'll have $2^{10}$  groups of houses by the time we get to the 10th level. That's 1024 leaves.\n",
    "\n",
    "When we divide the houses amongst many leaves, we also have fewer houses in each leaf. Leaves with very few houses will make predictions that are quite close to those homes' actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses). This is a phenomenon called **overfitting**, where a model matches the training data almost perfectly, but does poorly in validation and other new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPNZb7UEydzu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On the flip side, if we make our tree very shallow, it doesn't divide up the houses into very distinct groups. At an extreme, if a tree divides houses into only 2 or 4, each group still has a wide variety of houses. Resulting predictions may be far off for most houses, even in the training data (and it will be bad in validation too for the same reason). When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called **underfitting**.\n",
    "\n",
    "Since we care about accuracy on new data, which we estimate from our validation data, we want to find the sweet spot between underfitting and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_aWkHXmydzu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are a few alternatives for controlling the tree depth, and many allow for some routes through the tree to have greater depth than other routes. But the max_leaf_nodes argument provides a very sensible way to control overfitting vs underfitting. The more leaves we allow the model to make, the more we move from the underfitting area in the above graph to the overfitting area.\n",
    "\n",
    "We write a short utility function to help compare MAE scores from different values for max_leaf_nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csmlOCpKydzv"
   },
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=1)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgtSMsKfydzv",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, we loop over different values for the parameter to compare the in-sample and the out-of-sample performance of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MDvuCjXydzv",
    "outputId": "a5ff26c8-e72c-488a-b859-9ef32a462611"
   },
   "outputs": [],
   "source": [
    "for max_leaf_nodes in [2, 5, 50, 500, 5000, 10000]:\n",
    "    is_mae = get_mae(max_leaf_nodes, X, X, y, y)\n",
    "    oos_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t In-sample:  %d \\t Out-of-sample:  %d\" %(max_leaf_nodes, is_mae, oos_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIqPGtp4ydzv",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's the takeaway: Models can suffer from either:\n",
    "\n",
    "- __Overfitting:__ capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or\n",
    "- __Underfitting:__ failing to capture relevant patterns, again leading to less accurate predictions.\n",
    "\n",
    "We use validation data, which isn't used in model training, to measure a candidate model's accuracy. This lets us try many candidate models and keep the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### k-Fold Cross Validation \n",
    "\n",
    "When evaluating different settings (“hyperparameters”) for estimators, such as the number of leaf nodes, there is still a __risk of overfitting on the test set__ because the parameters can be tweaked until the __estimator performs optimally.__ This way, knowledge about the test set can __“leak”__ into the model and evaluation metrics no longer report on generalization performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To solve this problem, yet another part of the dataset can be held out as a so-called __“validation set”:__ training proceeds on the __training set,__ after which evaluation is done on the __validation set,__ and when the experiment seems to be successful, final evaluation can be done on the __test set.__\n",
    "\n",
    "However, by partitioning the available data into three sets, we drastically __reduce the number of samples__ which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "- A model is trained using of the folds as training data;\n",
    "- the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/vhaus63/ids_data/main/kfoldcv.png\" style=\"width:70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-learn provides standardized methods that __automate the entire k-fold cross-validation loop,__ see the examples of the [official documentation](https://scikit-learn.org/1.5/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mentimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1nxE08gydzv",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training a Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cM_gODLydzv"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/GuntherGust/tds2_data/main/images/03/Random_forest_explain.png?raw=1\" style=\"width:80%; float:left;\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHfrMkflydzv",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Decision trees leave us with a difficult trade-off. A deep tree with lots of leaves will overfit because each prediction is coming from historical data from only the few houses at its leaf. But a shallow tree with few leaves will perform poorly because it fails to capture as many distinctions in the raw data.\n",
    "\n",
    "Even today's most sophisticated modeling techniques face this tension between underfitting and overfitting. But, many models have clever ideas that can lead to better performance. We'll look at the random forest as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFlnPPwKydzv",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The random forest uses __many trees__, and it makes a prediction by __averaging the predictions of each component tree__. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters. If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caS-x4AZydzv",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Background on random forests\n",
    "\n",
    "\n",
    "- For an informal and illustrative introduction, see [this youtube video](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ&ab_channel=StatQuestwithJoshStarmer)\n",
    "- For a formal coverage see [Hastie et al: Elements of Statistical Learning, Chapter 15](https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTNnYuetydzv",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thanks to our Scikit-learn modeling pipeline we can reuse most of our code to train a random forest model with 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0D-b4cdKydzv"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BnN3Bacydzw",
    "outputId": "a1ea2f89-abce-4df1-974a-119faa2ea453",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define\n",
    "forest_model = RandomForestRegressor(random_state=1, n_estimators=100)\n",
    "\n",
    "# Fit\n",
    "forest_model.fit(train_X, train_y)\n",
    "\n",
    "# Evaluate\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(\"The MAE of our model is: {}\".format(mean_absolute_error(val_y, melb_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF6eYmeGydzw",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There is likely room for further improvement, but this is a __big improvement over the best decision tree error of 243,000__. There are parameters which allow you to change the performance of the Random Forest much as we changed the maximum depth of the single decision tree. But one of the best features of Random Forest models is that they generally work reasonably even without this tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just finished training our first machine learning models. To further improve the predictive power of the models we will have to __work on our dataset__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPzD3lmtydzw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing Value Imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_rGQVGfydzw",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will start with handling missing values in the data. Most machine learning libraries (including scikit-learn) give an error if we try to build a model using data with missing values. So we'll need to choose a strategy to handle missing values.\n",
    "\n",
    "We have already used a very simple strategy and dropped all rows containing missing values in the first example. To evaluate different approaches we will first load the full dataset and create a train-test split. (Note: As we cannot apply all imputation functions (e.g., mean) to categorical data we will only use numerical predictions in this simple example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H21cvi5_ydzw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "# Target variable\n",
    "y = data['Price']\n",
    "\n",
    "# Drop non-numeric variables\n",
    "melb_predictors = data.drop(['Price'], axis=1)\n",
    "X = melb_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idRiZASAydzw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simple Imputation using the Mean\n",
    "\n",
    "One popular way to handle missing values is called imputation. Here, we fill in the missing values with some number. For instance, we can fill in the __mean__ value along each column. The imputed value won't be exactly right in most cases, but it usually leads to more accurate models than you would get from dropping the column entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Su_tP-jydzw"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgErmO5bydzw",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Imputation\n",
    "simple_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(simple_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(simple_imputer.transform(X_valid))\n",
    "\n",
    "# \"Repair\" column names\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvTaFPmuydzw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To evaluate the performance of the approach, we modify our helper function (get_mae) to train and evaluate our model on different datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibyVk-Lrydzx"
   },
   "outputs": [],
   "source": [
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kn0fsaerydzx",
    "outputId": "9087b891-109f-4f48-dc77-348e4ca04b1d",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mae_imputation = score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid)\n",
    "print(\"MAE using Imputation: {}\".format(mae_imputation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLGPOzt4ydzx",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Advanced Imputation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMWKJ4cQydzx"
   },
   "source": [
    "We see that the imputation approach performs much better compared to the simple solution dropping all rows with NA values.\n",
    "\n",
    "Imputation is the standard approach, and it usually works well. However, imputed values may be systematically above or below their actual values (which weren't collected in the dataset). Or rows with missing values may be unique in some other way. In that case, your model would make better predictions by considering which values were originally missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1JwWI0Dydzx",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the advanced imputation approach, we impute the missing values, as before. And, additionally, for each column with missing entries in the original dataset, we __add a new column__ that shows the __location of the imputed entries__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "2Qsl_hBhydzx",
    "outputId": "408e109a-9f76-4754-df19-b3b587c566e9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original datasets to avoid changing the original data frame\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "# Find all columns with missing values:\n",
    "cols_with_missing = X_train.columns.values[X_train.isna().sum() > 0]\n",
    "\n",
    "# Make new columns indicating what will be imputed\n",
    "for col in cols_with_missing:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "X_train_plus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Fje9FCrydzx",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Imputation\n",
    "simple_imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(simple_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(simple_imputer.transform(X_valid_plus))\n",
    "\n",
    "# \"Repair\" column names\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yd5Zc-3Qydzx",
    "outputId": "eaca794c-d4be-4ef0-a6c9-50ab3c6e8f9e",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mae_imputation_advanced = score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid)\n",
    "print(\"MAE using Imputation: {}\".format(mae_imputation_advanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization, Standardization, Statistical Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70nKJghmydzx",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As we see, advanced imputation does not improve the performance of our model in the problem at hand. In general, advanced imputation will meaningfully improve results in some cases. In other cases, it doesn't help at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "INSERT Part from 04_Feature_Engineering here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "INSERT Part from 04_Feature_Engineering here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log transforms\n",
    "\n",
    "INSERT Part from 04_Feature_Engineering here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RhLgR3Rydzx",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Encoding Categorical Variables\n",
    "\n",
    "Until now we only used numerical features for our models. However, valuable information is often encoded in categorical variables (e.g., gender, city, job).\n",
    "\n",
    "If we simply __plug these categorial variables__ into machine learning models we will get an __error__. Hence, we need to find an appropriate preprocessing to capture the information hidden in categorical variables.\n",
    "\n",
    "The easiest approach to deal with categorical variables is to __drop__ them from the dataset (that is what we have done before). However, this approach will only produce satisfying results if the dropped columns __did not contain useful information__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4ACIFzTydzx",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Label Encoding\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/GuntherGust/tds2_data/main/images/03/label.png\" style=\"width:60%; float:left;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One common approach to handle categorical variables is called label encoding. Here, we assign __each unique value to a different integer (e.g., bad = 0, neutral = 1, good = 2)__.\n",
    "\n",
    "This assumption makes sense in this example, because there is an indisputable __ranking__ to the categories. Not all categorical variables have a clear ordering in the values, but we refer to those that do as ordinal variables. For tree-based models (like decision trees and random forests), you can expect label encoding to work well with ordinal variables.\n",
    "\n",
    "For simplicity, we will drop columns with missing values for the following evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwkH4XtTydzx",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "# Drop NA\n",
    "data.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Separate target from predictors\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)\n",
    "\n",
    "# Train-test split\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tvafv1Bydzy",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we do not want to use all categorical variables we focus on those with a __limited number of categories__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "si8WANWSydzy",
    "outputId": "2faf0aab-0e47-42fa-80c9-c8d3c9c41628"
   },
   "outputs": [],
   "source": [
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and\n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "print(low_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHh0Gsubydzy",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "...and combine them with the numerical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "-SJUmZ1nydzy",
    "outputId": "a8d13e0e-cd6b-4dcd-da05-05219c6ac195"
   },
   "outputs": [],
   "source": [
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep only selected columns\n",
    "cols_to_keep = low_cardinality_cols + numerical_cols\n",
    "X_train = X_train_full[cols_to_keep].copy()\n",
    "X_valid = X_valid_full[cols_to_keep].copy()\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsGhM4-Aydzy",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now perform label encoding on our new dataset using the functions provided by Scikit-learn. Subsequently, we can evaluate our approach by using our score_dataset utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JC-wLdTydzy"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "oKxsT0Csydzy",
    "outputId": "057dbf69-062f-40ef-84a3-bd40569dae06",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Make a copy to protect original data\n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "# Apply label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in low_cardinality_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "\n",
    "label_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UV6KKrfgydzy",
    "outputId": "3e4f3fdc-65c2-4df4-9232-b8c5c433b8a8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate performance\n",
    "mae_label_encoding = score_dataset(label_X_train, label_X_valid, y_train, y_valid)\n",
    "print(\"MAE using Label Encoding: {}\".format(mae_label_encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5UJrITdydzy",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This result is considerably better than the model that relied only on numerical variables without imputation (MAE 191.669 USD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzvVTZrXydzy",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One-hot Encoding\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/GuntherGust/tds2_data/main/images/03/onehot.png\" style=\"width:70%; float:left;\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding creates new binary columns indicating the presence (or absence) of each possible value in the original data.\n",
    "\n",
    "In contrast to label encoding, one-hot encoding does __not assume an ordering__ of the categories. Thus, you can expect this approach to work particularly well if there is no clear ordering in the categorical data. We refer to categorical variables without an intrinsic ranking as __nominal variables__.\n",
    "\n",
    "One-hot encoding generally does not perform well if the categorical variable takes on a large number of values (i.e., you generally __won't use__ it for variables taking on __many__ (e.g. more than 15) __different values__)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9dWvbPXydzy",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Again, we can use Scikit-learn functions to implement one-hot encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PejeyYsGydzz"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMoG_niQydzz",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's first look at the original values of the categorial variables before their transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "6wfkS7ciydzz",
    "outputId": "98ac532b-0efa-49cd-dca3-e985fad163cb"
   },
   "outputs": [],
   "source": [
    "X_train[low_cardinality_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdikkdw-ydzz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Apply one-hot encoder to each column with categorical data\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "one_hot_cols_train = pd.DataFrame(one_hot_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "one_hot_cols_valid = pd.DataFrame(one_hot_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# Repair index\n",
    "one_hot_cols_train.index = X_train.index\n",
    "one_hot_cols_valid.index = X_valid.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4J0jcfqdydzz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at the result of the one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "noPhugaoydzz",
    "outputId": "60dfd90f-0870-4706-c6bc-bda72c2fd88c"
   },
   "outputs": [],
   "source": [
    "one_hot_cols_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_4ubV9eydzz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hD_LuPWFydzz",
    "outputId": "93f423ff-8ac5-46c3-8d01-35b942c42106",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove categorical columns and replace with one-hot encoding\n",
    "num_X_train = X_train.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(low_cardinality_cols, axis=1)\n",
    "one_hot_X_train = pd.concat([num_X_train, one_hot_cols_train], axis=1)\n",
    "one_hot_X_valid = pd.concat([num_X_valid, one_hot_cols_valid], axis=1)\n",
    "\n",
    "print(one_hot_X_train.head())\n",
    "# Evaluate performance\n",
    "one_hot_encoding = score_dataset(one_hot_X_train.to_numpy(), one_hot_X_valid.to_numpy(), y_train, y_valid)\n",
    "print(\"MAE using One-hot Encoding: {}\".format(one_hot_encoding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhzU8Lh7ydzz",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is a small improvement in comparison to the label encoded data (MAE 181.607 USD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LoW_eM1ydzz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hIsnaTyydz0"
   },
   "source": [
    "Add an Exercise here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j001C2_Wydz0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating Model Pipelines\n",
    "\n",
    "Up to now, we learned how to prepare our datasets, train, tune, and evaluate powerful models. However, we wrote lots of code and functions to perform all the required tasks. Scikit-learn pipelines are a simple way to keep our data preprocessing and modeling code organized. Specifically, a pipeline bundles preprocessing and modeling steps so we can use the whole bundle as if it were a single step.\n",
    "\n",
    "Using pipelines provides multiple benefits:\n",
    "* Cleaner Code\n",
    "* Fewer Bugs\n",
    "* Easier to Productionize\n",
    "* More Options for Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3SWKyHpydz0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will build a pipeline using all numerical variables as well as the low cardinatlity categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "Rsdx2qxWydz0",
    "outputId": "c7fd435a-56e1-4b9c-a14c-5046f0e789d5"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "# Separate target from predictors\n",
    "y = data['Price']\n",
    "X = data[cols_to_keep]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dp0jZKltydz0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Writing a pipeline in Scikit-learn can be broken down into 3 steps:\n",
    "1. Define preprocessing steps\n",
    "2. Define the model\n",
    "3. Create and evaluate the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "843YlGhsydz0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define Preprocessing steps\n",
    "\n",
    "We use the ``ColumnTransformer`` class to bundle together different preprocessing steps. To this end, we will impute missing values in the numerical columns and impute missing values and use one-hot encoding in the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmaBE-7fydz0"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80H4DOdXydz1",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing numerical columns\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Preprocessing categorical columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle both preprocessors\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, low_cardinality_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn3FndA5ydz1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the Model\n",
    "Next, we define a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfNMudLbydz1"
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNCy8Utdydz1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create and Evaluate the Pipeline\n",
    "\n",
    "Finally, we use the ``Pipeline`` class to define a pipeline that bundles the preprocessing and modeling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQPwGodBydz1",
    "outputId": "a1534fdb-fa7d-4f63-bdbe-2537e9ea2f64"
   },
   "outputs": [],
   "source": [
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "complete_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Preprocess the raw training data and fit the model\n",
    "complete_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocess the raw validation data and make predictions\n",
    "preds = complete_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print(\"MAE using the complete pipeline: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6mSGM8Jydz1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " There are a few important things to notice:\n",
    "\n",
    "* With the pipeline, we preprocess the training data and fit the model in a __single line of code__. (In contrast, without a pipeline, we have to do imputation, one-hot encoding, and model training in separate steps. This becomes especially messy if we have to deal with both numerical and categorical variables!)\n",
    "* With the pipeline, we supply the __unprocessed features in X_valid to the predict()__ command, and the pipeline __automatically preprocesses__ the features before generating predictions. (However, without a pipeline, we have to remember to preprocess the validation data before making predictions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "A good exercise could be to let the students extend the pipeline by including the normalization / standardization techniques for the numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mentimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## knn Clustering (unsupervised learning)\n",
    "\n",
    "To be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Regression model\n",
    "\n",
    "To be added\n",
    "\n",
    "### Metrics for Evaluating Regression Models\n",
    "\n",
    "Introduce metrics that measure the goodness-of-fit and interpretability of the regression model:\n",
    "\n",
    "#### a. R-squared (\\(R^2\\))\n",
    "- Measures the proportion of the variance in the dependent variable explained by the independent variables.\n",
    "- Values range from 0 to 1:\n",
    "  - \\(R^2 = 1\\): Perfect fit.\n",
    "  - \\(R^2 = 0\\): No explanatory power.\n",
    "\n",
    "#### b. Adjusted R-squared\n",
    "- Adjusted for the number of predictors in the model, preventing overestimation of fit in multiple regression.\n",
    "\n",
    "#### c. Coefficients (\\(\\beta_1, \\beta_2, \\ldots\\))\n",
    "- Describe the strength and direction of the relationship between each independent variable and the dependent variable.\n",
    "\n",
    "#### d. Residuals\n",
    "- Difference between observed and predicted values:\n",
    "  - Helps assess model accuracy.\n",
    "  - Plot residuals to check for patterns.\n",
    "\n",
    "#### e. Mean Absolute Error (MAE)\n",
    "- Average absolute difference between observed and predicted values.\n",
    "\n",
    "#### f. Root Mean Squared Error (RMSE)\n",
    "- Measures the standard deviation of residuals, penalizing larger errors more than MAE.\n",
    "\n",
    "#### g. F-statistic and p-values\n",
    "- Assess the overall significance of the model and individual predictors.\n",
    "\n",
    "AIC / BIC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA: \n",
    "\n",
    "Apply PCA on a high-dimensional dataset and show how it simplifies data visualization.\n",
    "\n",
    "## Association Rule Mining: \n",
    "\n",
    "Use a small transactional dataset to find simple association rules (e.g., with the mlxtend library)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/vhaus63/ids_data/main/ao_modeling.png\" style=\"width:80%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5drq6GDbydz1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wrapping up\n",
    "\n",
    "In this lecture we learned how to build powerful machine learning models leveraging numerical as well as categorical variables. Additionally, we learned about model pipelines which are helpful for creating reproducible and understandable code.\n",
    "\n",
    "To keep improving, view the [scikit-learn documentation](https://scikit-learn.org/stable/) and keep working on your own projects!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "rise": {
   "custom_css": "./rise.css",
   "enable_chalkboard": false,
   "overlay": "<div class='background'></div><div class='header'>Introduction to Data Science (IDS)</div><div class='logo'><img src='images/d3logo.png'></div><div class='bar'></div>",
   "scroll": true,
   "slideNumber": true,
   "start_slideshow_at": "selected"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
